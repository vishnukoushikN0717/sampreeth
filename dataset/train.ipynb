{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (2643812492.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 42\u001b[1;36m\u001b[0m\n\u001b[1;33m    dataset_path = 'C:\\Users\\vishn\\OneDrive\\Desktop\\SUBASH_BTP\\archive\\dataset\\train'\u001b[0m\n\u001b[1;37m                                                                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Subset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import pandas as pd\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define dataset path\n",
    "dataset_path = r\"C:\\Users\\vishn\\OneDrive\\Desktop\\SUBASH_BTP\\archive\\dataset\\train\"\n",
    "test_path = r\"C:\\Users\\vishn\\OneDrive\\Desktop\\SUBASH_BTP\\archive\\dataset\\test\"  # Assuming test path exists\n",
    "\n",
    "# Define classes and labels\n",
    "classes = {\"fractured\": 1, \"not fractured\": 0}\n",
    "image_size = (224, 224)  # Standard size for many pretrained models\n",
    "\n",
    "# Data augmentation for training\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(image_size[0], image_size[1]),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2),\n",
    "        A.RandomGamma(),\n",
    "        A.HueSaturationValue()\n",
    "    ], p=0.5),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.GridDistortion(),\n",
    "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5)\n",
    "    ], p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=cv2.BORDER_CONSTANT, p=0.5),\n",
    "    A.GaussNoise(p=0.2),\n",
    "    A.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Transforms for validation/testing (no augmentation)\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(image_size[0], image_size[1]),\n",
    "    A.Normalize(mean=[0.5], std=[0.5]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# Custom dataset class with Albumentations\n",
    "class BoneFractureDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load fractured images\n",
    "        fractured_dir = os.path.join(folder_path, \"fractured\")\n",
    "        for filename in os.listdir(fractured_dir):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                self.images.append(os.path.join(fractured_dir, filename))\n",
    "                self.labels.append(1)  # 1 for fractured\n",
    "        \n",
    "        # Load non-fractured images\n",
    "        non_fractured_dir = os.path.join(folder_path, \"not fractured\")\n",
    "        for filename in os.listdir(non_fractured_dir):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                self.images.append(os.path.join(non_fractured_dir, filename))\n",
    "                self.labels.append(0)  # 0 for non-fractured\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Read image\n",
    "        image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "train_dataset = BoneFractureDataset(dataset_path, transform=train_transforms)\n",
    "\n",
    "# # Create a subset with the first 10 samples\n",
    "# train_dataset = Subset(full_train_dataset, indices=range(10))\n",
    "\n",
    "# Split into train and validation sets (80/20)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Update the transform for validation subset\n",
    "class TransformDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        \n",
    "        # If image is already a tensor, convert back to numpy for albumentations\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.numpy()\n",
    "            if image.shape[0] == 1:  # If it's already in CHW format\n",
    "                image = image.squeeze(0)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "val_subset = TransformDataset(val_subset, val_transforms)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(f\"Train size: {len(train_subset)}\")\n",
    "print(f\"Validation size: {len(val_subset)}\")\n",
    "\n",
    "# Define a more advanced CNN model (ResNet-based)\n",
    "class EnhancedBoneFractureCNN(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(EnhancedBoneFractureCNN, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18\n",
    "        self.resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Modify the first convolution layer to accept grayscale images\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()  # Remove original FC layer\n",
    "        \n",
    "        # Create new classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Initialize the new layers\n",
    "        for m in self.classifier.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# Create model instance\n",
    "model = EnhancedBoneFractureCNN(pretrained=True)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimizer with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=7, verbose=True)\n",
    "\n",
    "# Create a simple CNN model for ensemble (optional)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(128 * 28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(128, 1),  \n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "# Training and validation function\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=200):\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_val_auc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_auc': []}\n",
    "    \n",
    "    # for epoch in range(num_epochs):\n",
    "    #     epoch_start = time.time()\n",
    "    #     print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    #     print('-' * 10)\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n",
    "        epoch_start = time.time()\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = dataloaders['train']\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "                dataloader = dataloaders['val']\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            all_labels = []\n",
    "            all_preds = []\n",
    "            all_probs = []\n",
    "            \n",
    "            # Iterate over data\n",
    "            for inputs, labels in tqdm(dataloader, desc=phase):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).unsqueeze(1)  # Add channel dimension\n",
    "                \n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass - track history only in train phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    # Backward + optimize only in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                # Save predictions and actual labels\n",
    "                probs = outputs.detach().cpu().numpy()\n",
    "                preds = (probs >= 0.5).astype(int)\n",
    "                all_probs.extend(probs)\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            \n",
    "            # Convert to numpy arrays for metrics calculation\n",
    "            all_labels = np.array(all_labels).flatten()\n",
    "            all_preds = np.array(all_preds).flatten()\n",
    "            all_probs = np.array(all_probs).flatten()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "            \n",
    "            # Print metrics for the phase\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "            \n",
    "            # Save history\n",
    "            if phase == 'train':\n",
    "                history['train_loss'].append(epoch_loss)\n",
    "                history['train_acc'].append(epoch_acc)\n",
    "            else:  # validation phase\n",
    "                history['val_loss'].append(epoch_loss)\n",
    "                history['val_acc'].append(epoch_acc)\n",
    "                \n",
    "                # Calculate validation AUC\n",
    "                if len(np.unique(all_labels)) > 1:  # Only calculate AUC if both classes are present\n",
    "                    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "                    val_auc = auc(fpr, tpr)\n",
    "                    history['val_auc'].append(val_auc)\n",
    "                    print(f'Validation AUC: {val_auc:.4f}')\n",
    "                    \n",
    "                    # Update scheduler\n",
    "                    scheduler.step(epoch_loss)\n",
    "                    \n",
    "                    # Save best model\n",
    "                    if val_auc > best_val_auc:\n",
    "                        best_val_auc = val_auc\n",
    "                        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                        # Save best model\n",
    "                        torch.save({\n",
    "                            'epoch': epoch,\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': epoch_loss,\n",
    "                            'auc': val_auc,\n",
    "                        }, 'best_bone_fracture_model.pth')\n",
    "                        print(f'New best model saved! AUC: {val_auc:.4f}')\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start\n",
    "        print(f'Epoch complete in {epoch_time:.0f}s')\n",
    "        print()\n",
    "        \n",
    "        # Save checkpoint every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "            }, f'bone_fracture_model_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history\n",
    "\n",
    "# Run the training\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "trained_model, history = train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=1)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history['train_loss'], label='Train')\n",
    "plt.plot(history['val_loss'], label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history['train_acc'], label='Train')\n",
    "plt.plot(history['val_acc'], label='Validation')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history['val_auc'], label='Validation AUC')\n",
    "plt.title('Validation AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dir exists: False\n",
      "Val dir exists: False\n",
      "Train subfolders: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Train dir exists:\", os.path.exists('./dataset/train'))\n",
    "print(\"Val dir exists:\", os.path.exists('./dataset/val'))\n",
    "print(\"Train subfolders:\", os.listdir('./dataset/train') if os.path.exists('./dataset/train') else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation set for detailed metrics\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Evaluating'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_probs = np.array(all_probs).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    # ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Not Fractured', 'Fractured'],\n",
    "                yticklabels=['Not Fractured', 'Fractured'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': roc_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = evaluate_model(trained_model, val_loader)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "    'model_state_dict': trained_model.state_dict(),\n",
    "    'evaluation_results': evaluation_results\n",
    "}, 'final_bone_fracture_model.pth')\n",
    "\n",
    "# Function to predict on single image (for future use)\n",
    "def predict_image(model, image_path):\n",
    "    # Read and preprocess the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    transform = val_transforms\n",
    "    augmented = transform(image=image)\n",
    "    image_tensor = augmented['image'].unsqueeze(0).to(device)\n",
    "    \n",
    "    # Prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probability = output.item()\n",
    "        prediction = 1 if probability >= 0.5 else 0\n",
    "    \n",
    "    return {\n",
    "        'prediction': 'Fractured' if prediction == 1 else 'Not Fractured',\n",
    "        'probability': probability\n",
    "    }\n",
    "\n",
    "print(\"Training and evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc='Evaluating'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).unsqueeze(1)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            probs = outputs.cpu().numpy()\n",
    "            preds = (probs >= 0.5).astype(int)\n",
    "            \n",
    "            all_probs.extend(probs)\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_labels = np.array(all_labels).flatten()\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_probs = np.array(all_probs).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    # ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1 Score: {f1:.4f}')\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['Not Fractured', 'Fractured'],\n",
    "                yticklabels=['Not Fractured', 'Fractured'])\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': roc_auc,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_results = evaluate_model(trained_model, val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
